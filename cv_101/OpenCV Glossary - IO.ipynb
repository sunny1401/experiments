{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "other-organ",
   "metadata": {},
   "source": [
    "### IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-biology",
   "metadata": {},
   "source": [
    "OpenCV uses imread to read images, where the first argument is a path to the image. The second flag specifies the way the image should be read. \n",
    "\n",
    "1. cv2.IMREAD_COLOR: Loads a color image; neglecting any transparency of the image. This is the default flag. Can be represented as 1.\n",
    "2. cv2.IMREAD_GRAYSCALE: Loads an image in grayscale mode. Represented as 0.\n",
    "3. cv2.IMREAD_UNCHANGED: Loads image as such including alpha channel. Represented as -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lovely-backup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing grayscale image:\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "img = cv2.imread('/Users/sankrantijoshi/Desktop/8a46caa8628b6dcc8787bc2826fa4408.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-algeria",
   "metadata": {},
   "source": [
    "##### if the path to the image is wrong - no error is thrown but print(img) returns None. Else it returns a numpy ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "macro-animal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "inside-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dislaying an image - this is done using imshow function\n",
    "# The window automatically fits to the image size\n",
    "# First argument is a window name, which is a string and \n",
    "#Â the second argument is our image\n",
    "\n",
    "# we can have as many windows but they need to have a different name\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-miniature",
   "metadata": {},
   "source": [
    "<i>**cv2.waitKey()**</i> is a keyboard binding function. It takes argument which represents time in milliseconds. The function waits for the specified milliseconds for any keyboard event. If any key is pressed in that time, the program continues. Else, it waits indefinitely for a key stroke.\n",
    "It can also be set to detect specific key stroke like pressing key 'a'.\n",
    "\n",
    "cv2.destroyAllWindows() simply destroys all windows we created. To destry any specific window, we can use <i>**cv2.destroyWindow()**</i> <u>which requires the exact window name as an argument</u>. \n",
    "\n",
    "\n",
    "cv2 also has a special case where a window can be created as a placeholder and image is loaded to it later, using **cv2.namedWindow()**. This case allowes us to specify whether we want the window to be resizable.\n",
    "defaul flag - **cv2.WINDOW_AUTOSIZE**. To resize, we specify - **cv2.WINDOW_NORMAL**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "organic-glass",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('image', cv2.WINDOW_NORMAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "supreme-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(1) & 0xFF\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-blackjack",
   "metadata": {},
   "source": [
    "<u>When working on a 64-bit machine</u>, cv2.waitKey(0) needs to be modified as cv2.waitKey(0) & 0xFF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-arcade",
   "metadata": {},
   "source": [
    "### writing an image - \n",
    "\n",
    "We use function **cv2.imwrite()** to write an image that needs to be saved. First argument is the file name and the second argument is the image that needs to be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spiritual-affairs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('test1.png', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-discussion",
   "metadata": {},
   "source": [
    "The above saves the image in the working directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-century",
   "metadata": {},
   "source": [
    "### VIDEOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-greenhouse",
   "metadata": {},
   "source": [
    "OPenCV provides a simple imterface for capturing a live_stream from a camera. It also allows for converting it to grayscale and display it.\n",
    "\n",
    "\n",
    "To capture a video - **VideoCapture** object is required. <u>Its argument can be a device index or the name of a video file </u>.\n",
    "\n",
    "Device Index is a number to specify which camera to be connected. If working with a laptop, just one camera can be connected, so we pass 0. A second camera can also be connected by 1 and so on. Once this is setup, capcture can happen frame-by-frame.\n",
    "\n",
    "Once done, the camera needs to be released in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mediterranean-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-february",
   "metadata": {},
   "source": [
    "In the above snippet - **cap.read()** returns True/False. If a frame is read correctly, True will be returned. To check whether cap has been initialised or not we use **cap.isOpened()**. if this is True - we continue; else, it can be opened using **cap.open()** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "viral-aging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capture activated!\n"
     ]
    }
   ],
   "source": [
    "if not cap.isOpened():\n",
    "    cap.open(device_id)\n",
    "else:\n",
    "    print(\"Capture activated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "premium-moldova",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-climb",
   "metadata": {},
   "source": [
    "OpenCV allows to accesss different properties of the video using **cap.get(propId)** where propId is a number between 0 and 18. Each number denotes a property of the video.\n",
    "\n",
    "##### copied from OpenCV docs\n",
    "CV_CAP_PROP_POS_AVI_RATIO Relative position of the video file: 0 - start of the film, 1 - end of the film.\n",
    "\n",
    "CV_CAP_PROP_POS_MSEC Current position of the video file in milliseconds or video capture timestamp.\n",
    "\n",
    "CV_CAP_PROP_POS_FRAMES 0-based index of the frame to be decoded/captured next.\n",
    "\n",
    "CV_CAP_PROP_FRAME_WIDTH Width of the frames in the video stream. (use 3 for this)\n",
    "\n",
    "CV_CAP_PROP_FRAME_HEIGHT Height of the frames in the video stream.\n",
    "CV_CAP_PROP_FPS Frame rate. (use 4 for this)\n",
    "\n",
    "CV_CAP_PROP_FOURCC 4-character code of codec.\n",
    "\n",
    "CV_CAP_PROP_FRAME_COUNT Number of frames in the video file.\n",
    "\n",
    "CV_CAP_PROP_FORMAT Format of the Mat objects returned by retrieve() .\n",
    "\n",
    "CV_CAP_PROP_MODE Backend-specific value indicating the current capture mode.\n",
    "\n",
    "CV_CAP_PROP_BRIGHTNESS Brightness of the image (only for cameras).\n",
    "\n",
    "CV_CAP_PROP_CONTRAST Contrast of the image (only for cameras).\n",
    "\n",
    "CV_CAP_PROP_SATURATION Saturation of the image (only for cameras).\n",
    "\n",
    "CV_CAP_PROP_HUE Hue of the image (only for cameras).\n",
    "\n",
    "CV_CAP_PROP_GAIN Gain of the image (only for cameras).\n",
    "\n",
    "CV_CAP_PROP_EXPOSURE Exposure (only for cameras).\n",
    "\n",
    "CV_CAP_PROP_CONVERT_RGB Boolean flags indicating whether images should be converted to RGB.\n",
    "\n",
    "CV_CAP_PROP_WHITE_BALANCE_U The U value of the whitebalance setting (note: only supported by DC1394 v 2.x backend currently)\n",
    "\n",
    "CV_CAP_PROP_WHITE_BALANCE_V The V value of the whitebalance setting (note: only supported by DC1394 v 2.x backend currently)\n",
    "\n",
    "CV_CAP_PROP_RECTIFICATION Rectification flag for stereo cameras (note: only supported by DC1394 v 2.x backend currently)\n",
    "\n",
    "CV_CAP_PROP_ISO_SPEED The ISO speed of the camera (note: only supported by DC1394 v 2.x backend currently)\n",
    "\n",
    "CV_CAP_PROP_BUFFERSIZE Amount of frames stored in internal buffer memory (note: only supported by DC1394 v 2.x backend currently)\n",
    "\n",
    "\n",
    "**if querying a property that is not supported, 0 is retuned by the get function**\n",
    "\n",
    "We can also set some these properties - eg - width can be set using - cap.set(3, 320) and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-hawaiian",
   "metadata": {},
   "source": [
    "### Saving a video:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-category",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
